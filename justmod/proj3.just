set working-directory := '..'

# list project 3 just recipes
default:
    @just --list p3 --unsorted

# install extra dependencies of your KV code
deps:
    git submodule add https://github.com/HarukiMoriarty/Distributed-KV-Store.git

# build your executables in release mode
build:
    git submodule update --recursive --remote --init
    cd Distributed-KV-Store
    cargo build --release

# clean the build of your executables
clean:
    cd Distributed-KV-Store
    cargo clean --release

# run your KV store manager replica
manager rep_id="0" \
        man_port="3666" \
        p2p_port="3606" \
        peers="127.0.0.1:3607,127.0.0.1:3608" \
        server_rf="3" \
        servers="127.0.0.1:3777,127.0.0.1:3778,127.0.0.1:3779,127.0.0.1:3780,127.0.0.1:3781,127.0.0.1:3782"\
        backer_path="./backer.m.0":
    # we do not support manager replication
    # fuzz test
    cargo run --release \
        --manifest-path=Distributed-KV-Store/Cargo.toml \
        --bin manager \
        -- --listen-addr 127.0.0.1:{{man_port}} \
        --server-addrs {{servers}} \
        --server-rf {{server_rf}} \
        --tables key=5
    # ycsb test
    cargo run --release \
        --manifest-path=Distributed-KV-Store/Cargo.toml \
        --bin manager \
        -- --listen-addr 127.0.0.1:{{man_port}} \
        --server-addrs {{servers}} \
        --server-rf {{server_rf}} \
        --tables usertable_user=10000

# run your KV store server replica
server part_id="0" \
       rep_id="0" \
       managers="127.0.0.1:3666" \
       api_port="3777" \
       p2p_port="3707" \
       peers="127.0.0.1:3708,127.0.0.1:3709" \
       backer_path="./backer.s0.0":
    cargo run --release \
        --manifest-path=Distributed-KV-Store/Cargo.toml \
        --bin server \
        -- --partition-id {{part_id}} \
        --replica-id {{rep_id}} \
        --client-listen-addr 127.0.0.1:{{api_port}} \
        --manager-addr {{managers}} \
        --db-path {{backer_path}}/db/node{{part_id}}-{{rep_id}} \
        --log-path {{backer_path}}/log/node{{part_id}}-{{rep_id}} \
        --persistent-state-path {{backer_path}}/state/node{{part_id}}-{{rep_id}} \
        --persistence \
        --batch-size 100 \
        --batch-timeout 1000 \
        --peer-replica-addr {{peers}} \
        --peer-listen-addr 127.0.0.1:{{p2p_port}}

# run your KV store client in stdin/out interface mode
benchmark manager="127.0.0.1:3666" type="8":
    #!/usr/bin/env bash
    if [ "{{type}}" = "none" ]; then
        cargo run --release \
            --manifest-path=Distributed-KV-Store/Cargo.toml \
            --bin benchmark \
            -- --connect-addr {{manager}}
    else
        cargo run --release \
            --manifest-path=Distributed-KV-Store/Cargo.toml \
            --bin benchmark \
            -- --connect-addr {{manager}} --key-len {{type}}
    fi

# kill all processes of your KV store system
kill:
    # FIXME: your kill commands here
    #        make sure that it kills all server, clients, and any extra helper
    #        processes of your system; redirecting both out & err to /dev/null
    #        is recommended
    #   TIP: commands such as 'pkill' may return non-zero exit code on success,
    #        which would by default abort the 'just' recipe early; prepend the
    #        command with a '-' sign to ignore its exit code
    rm -rf data/*
    -pkill -f "Distributed-KV-Store/target/release/server"  > /dev/null 2>&1
    -pkill -f "Distributed-KV-Store/target/release/client"  > /dev/null 2>&1
    -pkill -f "Distributed-KV-Store/target/release/manager"  > /dev/null 2>&1
    -pkill -f "Distributed-KV-Store/target/release/benchmark"  > /dev/null 2>&1

# NOTE: feel free to add more recipes as you see fit...
#       also feel free to add extra parameters to the recipes as you see fit,
#       but don't change the existing parameters

python_run := if `which uv || true` != "" { "uv run" } else { "python3" }
tmpdir_prefix := "/tmp/madkv-p3"

# launch the KV service components on node (see README for conventions)
service node="s0.0" \
        managers="127.0.0.1:3666" \
        manager_p2ps="127.0.0.1:3606,127.0.0.1:3607,127.0.0.1:3608" \
        server_rf="3" \
        servers="127.0.0.1:3777,127.0.0.1:3778,127.0.0.1:3779,127.0.0.1:3780,127.0.0.1:3781,127.0.0.1:3782" \
        server_p2ps="127.0.0.1:3707,127.0.0.1:3708,127.0.0.1:3709,127.0.0.1:3710,127.0.0.1:3711,127.0.0.1:3712" \
        backer_prefix="./backer":
    just p3::build
    just utils::build
    cargo run -p runner -r --bin service -- \
        --server-just-args p3::server \
            $({{python_run}} justmod/xtract.py partid "{{node}}") \
            $({{python_run}} justmod/xtract.py repid "{{node}}") \
            "{{managers}}" \
            $({{python_run}} justmod/xtract.py portof "{{servers}}" "{{node}}" "{{server_rf}}") \
            $({{python_run}} justmod/xtract.py portof "{{server_p2ps}}" "{{node}}" "{{server_rf}}") \
            $({{python_run}} justmod/xtract.py peersof "{{server_p2ps}}" "{{node}}" "{{server_rf}}") \
            "{{backer_prefix}}.{{node}}" \
        --manager-just-args p3::manager \
            $({{python_run}} justmod/xtract.py repid "{{node}}") \
            $({{python_run}} justmod/xtract.py portof "{{managers}}" "{{node}}") \
            $({{python_run}} justmod/xtract.py portof "{{manager_p2ps}}" "{{node}}") \
            $({{python_run}} justmod/xtract.py peersof "{{manager_p2ps}}" "{{node}}") \
            "{{server_rf}}" \
            "{{servers}}" \
            "{{backer_prefix}}.{{node}}" \
        --node-id "{{node}}"

# ensure a subdir under 'tmp/' exists
tmpdir subdir:
    mkdir -p "{{tmpdir_prefix}}/{{subdir}}"

# run a fuzz testing scenario
fuzz server_rf="5" crashing="no" \
     managers="127.0.0.1:3666,127.0.0.1:3667,127.0.0.1:3668": (tmpdir "fuzz")
    just p3::build
    just utils::build
    cargo run -p runner -r --bin fuzzer -- \
        --num-clis 5 \
        --conflict \
        --client-just-args p3::benchmark "{{managers}}" "8"\
        | tee "{{tmpdir_prefix}}/fuzz/fuzz-{{server_rf}}-{{crashing}}.log"
    just p3::kill

# run a YCSB benchmark workload
bench nclis wload server_rf="3" \
      managers="127.0.0.1:3666,127.0.0.1:3667,127.0.0.1:3668": (tmpdir "bench")
    just p3::build
    just utils::build
    just utils::ycsb
    cargo run -p runner -r --bin bencher -- \
        --num-clis "{{nclis}}" \
        --workload "{{wload}}" \
        --client-just-args p3::benchmark "{{managers}}" "none" \
        | tee "{{tmpdir_prefix}}/bench/bench-{{nclis}}-{{wload}}-{{server_rf}}.log"
    # just p3::kill

# generate .md report template from existing results (wip)
report:
    {{python_run}} sumgen/proj3.py
